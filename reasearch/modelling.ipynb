{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CementStrength.entity import TrainingConfig\n",
    "from CementStrength import logger\n",
    "from CementStrength.utils import read_yaml,create_directories,save_model,load_model\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class Training:\n",
    "    def __init__(self,config: TrainingConfig):\n",
    "        self.config = config\n",
    "         \n",
    "        create_directories(self.config.preprocessed_data_dir)\n",
    "        create_directories(self.config.Models_dir)\n",
    "        create_directories(self.config.images)\n",
    "\n",
    "    def copy_training_file(self):\n",
    "        create_directories(self.config.training_dir)\n",
    "        shutil.copy(self.config.source_dir,self.config.local_training_file)\n",
    "        logger.info(\"file copied\")\n",
    "\n",
    "    def preprocessing(self):\n",
    "        df = pd.read_csv(self.config.local_training_file)\n",
    "        df = df.drop(columns='Unnamed: 0')\n",
    "        if df.isnull().values.any():\n",
    "            for column in df.columns:\n",
    "                if df[column].dtype == 'int64'or df[column].dtype == 'float64':\n",
    "                    df[column] = df[column].fillna(df[column].mean())\n",
    "                else:\n",
    "                    df[column] = df[column].fillna(df[column].mode())\n",
    "        # removing outliers\n",
    "        Q1 = df.quantile(.25)\n",
    "        Q3 = df.quantile(.75)\n",
    "        IQR = Q3-Q1\n",
    "        df = df[~((df<(Q1-1.5*IQR)) | (df>(Q3+1.5*IQR))).any(axis=1)]\n",
    "        for column in df.columns:\n",
    "            df[column] += 1\n",
    "            df[column] = np.log(df[column])\n",
    "        fig= plt.figure(figsize=(10,10))\n",
    "        sns.boxplot(df)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.title(\"Data after outlier correction\")\n",
    "        plt.savefig(self.config.images+'/'+'afer_outlier.png', format=\"png\")\n",
    "        plt.close(fig=fig)\n",
    "        fig= plt.figure(figsize=(8,8))\n",
    "        sns.heatmap(df.corr(),annot=True,cmap=\"Spectral_r\")\n",
    "        plt.savefig(self.config.images+'/'+'heatmap.png', format=\"png\")\n",
    "        plt.close(fig=fig)\n",
    "\n",
    "        return df.to_csv(self.config.preprocessed_data,index=False)\n",
    "                \n",
    "    def clustering(self):\n",
    "        df = pd.read_csv(self.config.preprocessed_data)\n",
    "        X = df.drop(columns='Concrete_compressive _strength')\n",
    "        y = df['Concrete_compressive _strength']\n",
    "        #X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "        #X_valid,X_test,y_valid,y_test = train_test_split(X_test,y_test,test_size=0.5,random_state=42)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(scaler.fit_transform(X),columns=X.columns,index=X.index)\n",
    "        \n",
    "        \n",
    "        inertia = []\n",
    "        K = range(1,11)\n",
    "        for k in K:\n",
    "            km = KMeans(n_clusters=k)\n",
    "            km = km.fit(X_scaled.values)\n",
    "            inertia.append(km.inertia_)\n",
    "        fig = plt.plot(K, inertia, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Sum_of_squared_distances')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        plt.savefig(self.config.images+'/'+'elbow_method_K.png')\n",
    "        plt.close()\n",
    "        \n",
    "        kl = KneeLocator(range(1, 11), inertia, curve=\"convex\", direction=\"decreasing\")\n",
    "        no_of_clusters = kl.elbow\n",
    "        cluster_model = KMeans(n_clusters=no_of_clusters,init=\"k-means++\",random_state=42).fit(X_scaled.values)\n",
    "        save_model(cluster_model,self.config.Models_dir,'cluster_model')\n",
    "\n",
    "        clusters_train = cluster_model.predict(X_scaled.values)\n",
    "        #clusters_valid = cluster_model.predict(X_valid_scaled.values)\n",
    "        #clusters_test = cluster_model.predict(X_test_scaled.values)\n",
    "        X_scaled['cluster'] = pd.Series(clusters_train, index=X_scaled.index) #cluster column added\n",
    "        dfs=[X_scaled[X_scaled['cluster']==i] for i in range(no_of_clusters)]\n",
    "        y_cluster = [y.loc[dfs[i].index] for i in range(len(dfs))]\n",
    "        new_dfs = []\n",
    "        for i in range(len(dfs)):\n",
    "            dfs[i]['Concrete Compressive strength'] = y_cluster[i] \n",
    "            new_dfs.append(dfs[i])\n",
    "        for i in range(len(new_dfs)):\n",
    "            new_dfs[i].to_csv(self.config.preprocessed_data_dir+'/'+'cluster'+str(i)+'.csv',index=False)\n",
    "\n",
    "    def regressor(self):\n",
    "        \n",
    "        models = []\n",
    "        for i,cluster in enumerate(os.listdir(self.config.preprocessed_data_dir)):\n",
    "            df = pd.read_csv(os.path.join(self.config.preprocessed_data_dir,cluster))\n",
    "            df = df.drop(columns='cluster')\n",
    "            X = df.drop(columns='Concrete Compressive strength')\n",
    "            y = df['Concrete Compressive strength']\n",
    "            X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "            rm = RandomForestRegressor(random_state=42)\n",
    "            params = { 'n_estimators': [50,100,150],'criterion':['squared_error','absolute_error','friedman_mse','poisson']}\n",
    "            grid = GridSearchCV(estimator=rm,param_grid=params)\n",
    "            grid.fit(X_train, y_train)\n",
    "            random_model = RandomForestRegressor(criterion=grid.best_params_['criterion'],n_estimators=grid.best_params_['n_estimators']).fit(X_train, y_train)\n",
    "            save_model(random_model,self.config.Models_dir,'random_model_cluster'+str(i))\n",
    "            models.append(random_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    source_dir: Path\n",
    "    training_dir: Path\n",
    "    local_training_file: Path\n",
    "    preprocessed_data_dir: Path\n",
    "    preprocessed_data: Path\n",
    "    Models_dir: Path\n",
    "    images: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CementStrength.utils import read_yaml,create_directories\n",
    "from CementStrength.entity import DataIngestionConfig,DataValidationConfig,DbOperationsConfig\n",
    "from CementStrength.constants import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    \n",
    "      def __init__(self, \n",
    "                config_file= CONFIG_FILE_PATH,\n",
    "                param_file = PARAMS_FILE_PATH):\n",
    "\n",
    "            self.config_file = read_yaml(config_file)\n",
    "            self.param_file = read_yaml(param_file)\n",
    "            \n",
    "            \n",
    "      \n",
    "      def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "            create_directories(self.config_file.data_ingestion.root_dir)  \n",
    "            create_directories(self.config_file.data_validation.good_dir)\n",
    "            create_directories(self.config_file.data_validation.bad_dir)\n",
    "            data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir = self.config_file.data_ingestion.root_dir,\n",
    "            source_URL = self.config_file.data_ingestion.source_URL,\n",
    "            local_data_file = self.config_file.data_ingestion.local_data_file,\n",
    "            unzip_dir = self.config_file.data_ingestion.unzip_dir\n",
    "                        \n",
    "                  )\n",
    "            return data_ingestion_config\n",
    "      \n",
    "      def get_data_validation_config(self) -> DataValidationConfig:\n",
    "            data_validation_config = DataValidationConfig(\n",
    "                source_dir = self.config_file.data_validation.source_dir,   \n",
    "                good_dir =  self.config_file.data_validation.good_dir,\n",
    "                bad_dir = self.config_file.data_validation.bad_dir\n",
    "                        \n",
    "                  )\n",
    "            return data_validation_config\n",
    "      \n",
    "      def get_db_operations_config(self) -> DbOperationsConfig:\n",
    "            db_operations_config = DbOperationsConfig(\n",
    "                  source_dir = self.config_file.db_operations.source_dir,\n",
    "                  db_dir= self.config_file.db_operations.db_dir,\n",
    "                  db_name= self.config_file.db_operations.db_name,\n",
    "                  training_dir = self.config_file.db_operations.training_dir,\n",
    "                  training_file= self.config_file.db_operations.training_file             \n",
    "                  )\n",
    "            return db_operations_config\n",
    "\n",
    "      def get_training_config(self) -> TrainingConfig:\n",
    "                       \n",
    "            training_config = TrainingConfig(\n",
    "                  source_dir = self.config_file.training.source_dir,\n",
    "                  training_dir = self.config_file.training.training_dir,\n",
    "                  local_training_file = self.config_file.training.local_training_file,\n",
    "                  preprocessed_data_dir = self.config_file.training.preprocessed_data_dir,\n",
    "                  preprocessed_data= self.config_file.training.preprocessed_data,\n",
    "                  Models_dir= self.config_file.training.Models_dir,\n",
    "                  images= self.config_file.training.images\n",
    "                           \n",
    "                  )\n",
    "            print(\"Debug - Training Config:\", training_config)\n",
    "            return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-16 15:21:37,645: INFO: common: yaml file: config\\config.yml loaded successfully]\n",
      "[2023-11-16 15:21:37,654: INFO: common: yaml file: params.yml loaded successfully]\n",
      "Debug - Training Config: TrainingConfig(source_dir='db_operations/training/input.csv', training_dir='Training', local_training_file='Training/training.csv', preprocessed_data_dir='Training/preprocessed', preprocessed_data='Training/preprocessed_data.csv', Models_dir='Training/models', images='Training/images')\n"
     ]
    }
   ],
   "source": [
    "train_config = ConfigurationManager()\n",
    "configs= train_config.get_training_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-16 15:21:38,435: INFO: common: directory created]\n",
      "[2023-11-16 15:21:38,437: INFO: common: directory created]\n",
      "[2023-11-16 15:21:38,439: INFO: common: directory created]\n",
      "[2023-11-16 15:21:38,441: INFO: common: directory created]\n",
      "[2023-11-16 15:21:38,443: INFO: 3524851760: file copied]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-16 15:21:39,806: INFO: common: model saved]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gagan\\Anaconda3\\envs\\cementnew\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_19248\\3524851760.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs[i]['Concrete Compressive strength'] = y_cluster[i]\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_19248\\3524851760.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs[i]['Concrete Compressive strength'] = y_cluster[i]\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_19248\\3524851760.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs[i]['Concrete Compressive strength'] = y_cluster[i]\n",
      "C:\\Users\\gagan\\AppData\\Local\\Temp\\ipykernel_19248\\3524851760.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfs[i]['Concrete Compressive strength'] = y_cluster[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-16 15:21:57,278: INFO: common: model saved]\n",
      "[2023-11-16 15:22:09,028: INFO: common: model saved]\n",
      "[2023-11-16 15:22:23,128: INFO: common: model saved]\n",
      "[2023-11-16 15:22:33,274: INFO: common: model saved]\n"
     ]
    }
   ],
   "source": [
    "train = Training(config=configs)\n",
    "train.copy_training_file()\n",
    "train.preprocessing()\n",
    "train.clustering()\n",
    "train.regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cementnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
